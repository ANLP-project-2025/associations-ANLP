{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15107,
     "status": "ok",
     "timestamp": 1756062528025,
     "user": {
      "displayName": "Daniel Ruderman",
      "userId": "14047671416305053483"
     },
     "user_tz": -180
    },
    "id": "hZS9oYu43-zv",
    "outputId": "d6a2794e-b51c-4017-b075-6aebd32b12b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Setup: Install Packages\n",
    "# ===============================\n",
    "!pip install -q \\\n",
    "  \"transformers>=4.41,<5\" \\\n",
    "  \"datasets==2.19.1\" \\\n",
    "  \"peft==0.10.0\" \\\n",
    "  \"accelerate>=0.34.2\" \\\n",
    "  \"bitsandbytes>=0.43.3\" \\\n",
    "  \"evaluate>=0.4.2\" \\\n",
    "  \"rouge_score>=0.1.2\" \\\n",
    "  \"scikit-learn\" \\\n",
    "  \"openpyxl\" \\\n",
    "  \"pandas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19949,
     "status": "ok",
     "timestamp": 1756062547978,
     "user": {
      "displayName": "Daniel Ruderman",
      "userId": "14047671416305053483"
     },
     "user_tz": -180
    },
    "id": "ITx22_Hka3ES",
    "outputId": "5812e731-88ab-4d6e-d243-0a4a547b0d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 2.8.0+cu126 → Installing Triton 3.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, sys, subprocess\n",
    "mm = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "triton_by_torch = {\"2.5\":\"3.2.0\",\"2.4\":\"3.0.0\",\"2.3\":\"2.3.1\",\"2.2\":\"2.2.0\"}\n",
    "target = triton_by_torch.get(mm, \"3.2.0\")\n",
    "print(f\"Torch {torch.__version__} → Installing Triton {target}\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", f\"triton=={target}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38092,
     "status": "ok",
     "timestamp": 1756062632970,
     "user": {
      "displayName": "Daniel Ruderman",
      "userId": "14047671416305053483"
     },
     "user_tz": -180
    },
    "id": "P8tfqh_s4DkC",
    "outputId": "74885997-1483-485d-fea2-459bd9025b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Import packages & login\n",
    "# ===============================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, random, torch, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
    "    TrainingArguments, Trainer, set_seed\n",
    ")\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from huggingface_hub import login\n",
    "\n",
    "# --------------- Hugging Face token ---------------\n",
    "os.environ[\"HF_TOKEN\"] = \"YOUR_TOKEN_HERE\"\n",
    "login(os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "# --------------- Reproducibility ---------------\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108688,
     "status": "ok",
     "timestamp": 1756062767531,
     "user": {
      "displayName": "Daniel Ruderman",
      "userId": "14047671416305053483"
     },
     "user_tz": -180
    },
    "id": "inP6VRtL4Dg7",
    "outputId": "f950269d-048b-48b0-d277-d62806819301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cues   → Train:7194, Val:899, Test:899\n",
      "Rows   → Train:575520, Val:71920, Test:71920\n",
      "✅  Cue 'sea' ensured in Train split.\n",
      "✅  All Excel files saved.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Split cleaned_data_FA_Humans.xlsx into Train | Val | Test\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "BASE_PATH = r\"/content/drive/My Drive/associations-ANLP\"\n",
    "\n",
    "XLSX_PATH = os.path.join(BASE_PATH, r\"data/swow_words_associations_dataset/cleaned_data_FA_Humans.xlsx\")\n",
    "\n",
    "TRAIN_XLSX_PATH = os.path.join(BASE_PATH, r\"data/swow_words_associations_dataset/train.xlsx\")\n",
    "VAL_XLSX_PATH   = os.path.join(BASE_PATH, r\"data/swow_words_associations_dataset/val.xlsx\")\n",
    "TEST_XLSX_PATH  = os.path.join(BASE_PATH, r\"data/swow_words_associations_dataset/test.xlsx\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(TRAIN_XLSX_PATH), exist_ok=True)\n",
    "\n",
    "# ---------- Load Excel ----------\n",
    "df = pd.read_excel(XLSX_PATH)\n",
    "\n",
    "SEED = 42\n",
    "# ---- cue-level stratified split: 80 % / 10 % / 10 % ----\n",
    "unique_cues = df[\"cue\"].unique().tolist()\n",
    "\n",
    "# Force \"sea\" into training if present\n",
    "if \"sea\" in unique_cues:\n",
    "    unique_cues.remove(\"sea\")\n",
    "    must_have_train = {\"sea\"}\n",
    "else:\n",
    "    must_have_train = set()\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "rng.shuffle(unique_cues)\n",
    "\n",
    "n_total = len(unique_cues) + len(must_have_train)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val   = int(0.1 * n_total)\n",
    "\n",
    "# Build splits\n",
    "train_cues = set(unique_cues[:n_train]) | must_have_train\n",
    "val_cues   = set(unique_cues[n_train:n_train+n_val])\n",
    "test_cues  = set(unique_cues[n_train+n_val:])\n",
    "\n",
    "train_df = df[df[\"cue\"].isin(train_cues)]\n",
    "val_df   = df[df[\"cue\"].isin(val_cues)]\n",
    "test_df  = df[df[\"cue\"].isin(test_cues)]\n",
    "\n",
    "# ---------- Save to Excel ----------\n",
    "train_df.to_excel(TRAIN_XLSX_PATH, index=False)\n",
    "val_df.to_excel(VAL_XLSX_PATH,   index=False)\n",
    "test_df.to_excel(TEST_XLSX_PATH, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Cues   → Train:{len(train_cues)}, Val:{len(val_cues)}, Test:{len(test_cues)}\")\n",
    "print(f\"Rows   → Train:{len(train_df)}, Val:{len(val_df)}, Test:{len(test_df)}\")\n",
    "if \"sea\" in df[\"cue\"].values:\n",
    "    print(\"Cue 'sea' ensured in Train split.\")\n",
    "else:\n",
    "    print(\"Cue 'sea' not found in dataset.\")\n",
    "print(\"All Excel files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44289,
     "status": "ok",
     "timestamp": 1756062811812,
     "user": {
      "displayName": "Daniel Ruderman",
      "userId": "14047671416305053483"
     },
     "user_tz": -180
    },
    "id": "27yaOttQYqbJ",
    "outputId": "1141951a-4f9f-4ec5-88fd-74322afa0a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Cues: 7194, Rows: 575520\n",
      "Val Cues:   899,   Rows: 71920\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Count cues/rows in Train & Val (Excel)\n",
    "# =========================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Load Excel files\n",
    "df_train = pd.read_excel(TRAIN_XLSX_PATH)\n",
    "df_val   = pd.read_excel(VAL_XLSX_PATH)\n",
    "\n",
    "# Unique cues\n",
    "train_cues = set(df_train[\"cue\"].dropna().unique())\n",
    "val_cues   = set(df_val[\"cue\"].dropna().unique())\n",
    "\n",
    "print(f\"Train Cues: {len(train_cues)}, Rows: {len(df_train)}\")\n",
    "print(f\"Val Cues:   {len(val_cues)},   Rows: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45121,
     "status": "ok",
     "timestamp": 1756062856934,
     "user": {
      "displayName": "Daniel Ruderman",
      "userId": "14047671416305053483"
     },
     "user_tz": -180
    },
    "id": "ehKU7Xdjq1sy",
    "outputId": "6357e921-13af-4edc-f0f7-ac3fd827924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All cues are unique across the two files.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Verify no cue overlap between Train & Val (Excel)\n",
    "# =========================================================\n",
    "\n",
    "# Find overlaps\n",
    "overlap = train_cues & val_cues\n",
    "\n",
    "if overlap:\n",
    "    print(f\"Found {len(overlap)} cues in both files:\")\n",
    "    for cue in sorted(overlap):\n",
    "        print(\"   \", cue)\n",
    "else:\n",
    "    print(\"All cues are unique across the two files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8JJ9rxU4pX4"
   },
   "outputs": [],
   "source": [
    "# Disconnect the runtime\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPLHRNPSSiBNFjbMqUEfof6",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1dqCZ8RYPI9JHnNe7cYbgTQvDa1pr7aDz",
     "timestamp": 1754852023215
    },
    {
     "file_id": "1_4krYAQIpm-TCyf8s6hBcwsFVxFQMmgn",
     "timestamp": 1754828998873
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
