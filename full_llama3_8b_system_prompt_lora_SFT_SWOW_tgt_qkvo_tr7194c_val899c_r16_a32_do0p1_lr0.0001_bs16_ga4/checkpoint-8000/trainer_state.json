{
  "best_global_step": 8000,
  "best_metric": 2.374586343765259,
  "best_model_checkpoint": "/content/drive/My Drive/ANLP_project/full_llama3_8b_system_prompt_lora_SFT_SWOW_tgt_qkvo_tr7194c_val899c_r16_a32_do0p1_lr0.0001_bs16_ga4/checkpoint-8000",
  "epoch": 0.8896302474284126,
  "eval_steps": 800,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005560189046427579,
      "grad_norm": 4.044653415679932,
      "learning_rate": 1.088888888888889e-05,
      "loss": 3.7058,
      "step": 50
    },
    {
      "epoch": 0.011120378092855158,
      "grad_norm": 1.5529038906097412,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 2.7667,
      "step": 100
    },
    {
      "epoch": 0.016680567139282735,
      "grad_norm": 1.7393611669540405,
      "learning_rate": 3.311111111111112e-05,
      "loss": 2.5833,
      "step": 150
    },
    {
      "epoch": 0.022240756185710316,
      "grad_norm": 1.915265440940857,
      "learning_rate": 4.422222222222222e-05,
      "loss": 2.546,
      "step": 200
    },
    {
      "epoch": 0.027800945232137893,
      "grad_norm": 1.693686604499817,
      "learning_rate": 5.5333333333333334e-05,
      "loss": 2.5524,
      "step": 250
    },
    {
      "epoch": 0.03336113427856547,
      "grad_norm": 1.6331294775009155,
      "learning_rate": 6.644444444444444e-05,
      "loss": 2.5156,
      "step": 300
    },
    {
      "epoch": 0.03892132332499305,
      "grad_norm": 1.6404589414596558,
      "learning_rate": 7.755555555555556e-05,
      "loss": 2.4988,
      "step": 350
    },
    {
      "epoch": 0.04448151237142063,
      "grad_norm": 1.2475539445877075,
      "learning_rate": 8.866666666666668e-05,
      "loss": 2.523,
      "step": 400
    },
    {
      "epoch": 0.05004170141784821,
      "grad_norm": 1.4146480560302734,
      "learning_rate": 9.977777777777779e-05,
      "loss": 2.4977,
      "step": 450
    },
    {
      "epoch": 0.055601890464275786,
      "grad_norm": 1.3669965267181396,
      "learning_rate": 9.999188292889494e-05,
      "loss": 2.4957,
      "step": 500
    },
    {
      "epoch": 0.06116207951070336,
      "grad_norm": 1.2541857957839966,
      "learning_rate": 9.996686847991488e-05,
      "loss": 2.4644,
      "step": 550
    },
    {
      "epoch": 0.06672226855713094,
      "grad_norm": 1.2335913181304932,
      "learning_rate": 9.99249617289002e-05,
      "loss": 2.5155,
      "step": 600
    },
    {
      "epoch": 0.07228245760355852,
      "grad_norm": 1.0973726511001587,
      "learning_rate": 9.98661768432686e-05,
      "loss": 2.4993,
      "step": 650
    },
    {
      "epoch": 0.0778426466499861,
      "grad_norm": 1.2742202281951904,
      "learning_rate": 9.979053369642964e-05,
      "loss": 2.47,
      "step": 700
    },
    {
      "epoch": 0.08340283569641367,
      "grad_norm": 1.1684296131134033,
      "learning_rate": 9.969805786106623e-05,
      "loss": 2.465,
      "step": 750
    },
    {
      "epoch": 0.08896302474284126,
      "grad_norm": 1.0398800373077393,
      "learning_rate": 9.958878060048923e-05,
      "loss": 2.4732,
      "step": 800
    },
    {
      "epoch": 0.08896302474284126,
      "eval_loss": 2.523524522781372,
      "eval_runtime": 1068.0249,
      "eval_samples_per_second": 67.339,
      "eval_steps_per_second": 4.209,
      "step": 800
    },
    {
      "epoch": 0.09452321378926884,
      "grad_norm": 1.1339097023010254,
      "learning_rate": 9.946273885806828e-05,
      "loss": 2.4676,
      "step": 850
    },
    {
      "epoch": 0.10008340283569642,
      "grad_norm": 1.1347954273223877,
      "learning_rate": 9.93199752447423e-05,
      "loss": 2.4567,
      "step": 900
    },
    {
      "epoch": 0.105643591882124,
      "grad_norm": 1.1719025373458862,
      "learning_rate": 9.916053802461407e-05,
      "loss": 2.423,
      "step": 950
    },
    {
      "epoch": 0.11120378092855157,
      "grad_norm": 1.1019854545593262,
      "learning_rate": 9.898448109863359e-05,
      "loss": 2.4479,
      "step": 1000
    },
    {
      "epoch": 0.11676396997497915,
      "grad_norm": 1.0579614639282227,
      "learning_rate": 9.879186398637567e-05,
      "loss": 2.4874,
      "step": 1050
    },
    {
      "epoch": 0.12232415902140673,
      "grad_norm": 1.0458648204803467,
      "learning_rate": 9.85827518059183e-05,
      "loss": 2.4523,
      "step": 1100
    },
    {
      "epoch": 0.1278843480678343,
      "grad_norm": 1.2309290170669556,
      "learning_rate": 9.835721525182809e-05,
      "loss": 2.4524,
      "step": 1150
    },
    {
      "epoch": 0.13344453711426188,
      "grad_norm": 1.0999181270599365,
      "learning_rate": 9.811533057126053e-05,
      "loss": 2.4424,
      "step": 1200
    },
    {
      "epoch": 0.13900472616068946,
      "grad_norm": 1.1234737634658813,
      "learning_rate": 9.785717953818316e-05,
      "loss": 2.4312,
      "step": 1250
    },
    {
      "epoch": 0.14456491520711703,
      "grad_norm": 1.0359975099563599,
      "learning_rate": 9.758284942573028e-05,
      "loss": 2.418,
      "step": 1300
    },
    {
      "epoch": 0.1501251042535446,
      "grad_norm": 1.1098312139511108,
      "learning_rate": 9.729243297669839e-05,
      "loss": 2.4422,
      "step": 1350
    },
    {
      "epoch": 0.1556852932999722,
      "grad_norm": 1.0794270038604736,
      "learning_rate": 9.698602837219273e-05,
      "loss": 2.411,
      "step": 1400
    },
    {
      "epoch": 0.16124548234639977,
      "grad_norm": 1.0046131610870361,
      "learning_rate": 9.666373919843519e-05,
      "loss": 2.4437,
      "step": 1450
    },
    {
      "epoch": 0.16680567139282734,
      "grad_norm": 1.123212456703186,
      "learning_rate": 9.632567441174483e-05,
      "loss": 2.398,
      "step": 1500
    },
    {
      "epoch": 0.17236586043925495,
      "grad_norm": 1.0243592262268066,
      "learning_rate": 9.597194830170308e-05,
      "loss": 2.4065,
      "step": 1550
    },
    {
      "epoch": 0.17792604948568252,
      "grad_norm": 1.1051061153411865,
      "learning_rate": 9.560268045251585e-05,
      "loss": 2.4356,
      "step": 1600
    },
    {
      "epoch": 0.17792604948568252,
      "eval_loss": 2.4713234901428223,
      "eval_runtime": 1067.5268,
      "eval_samples_per_second": 67.371,
      "eval_steps_per_second": 4.211,
      "step": 1600
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 1.0974665880203247,
      "learning_rate": 9.521799570258566e-05,
      "loss": 2.4288,
      "step": 1650
    },
    {
      "epoch": 0.18904642757853768,
      "grad_norm": 1.090193510055542,
      "learning_rate": 9.481802410230751e-05,
      "loss": 2.4142,
      "step": 1700
    },
    {
      "epoch": 0.19460661662496526,
      "grad_norm": 1.0369079113006592,
      "learning_rate": 9.440290087010282e-05,
      "loss": 2.4109,
      "step": 1750
    },
    {
      "epoch": 0.20016680567139283,
      "grad_norm": 1.001240611076355,
      "learning_rate": 9.397276634670602e-05,
      "loss": 2.4346,
      "step": 1800
    },
    {
      "epoch": 0.2057269947178204,
      "grad_norm": 1.070474624633789,
      "learning_rate": 9.352776594771957e-05,
      "loss": 2.4175,
      "step": 1850
    },
    {
      "epoch": 0.211287183764248,
      "grad_norm": 1.1091618537902832,
      "learning_rate": 9.306805011445338e-05,
      "loss": 2.4018,
      "step": 1900
    },
    {
      "epoch": 0.21684737281067556,
      "grad_norm": 0.9923981428146362,
      "learning_rate": 9.259377426306505e-05,
      "loss": 2.4207,
      "step": 1950
    },
    {
      "epoch": 0.22240756185710314,
      "grad_norm": 1.0498536825180054,
      "learning_rate": 9.210509873201829e-05,
      "loss": 2.4112,
      "step": 2000
    },
    {
      "epoch": 0.22796775090353072,
      "grad_norm": 1.0067161321640015,
      "learning_rate": 9.160218872787734e-05,
      "loss": 2.3947,
      "step": 2050
    },
    {
      "epoch": 0.2335279399499583,
      "grad_norm": 1.058546543121338,
      "learning_rate": 9.108521426945556e-05,
      "loss": 2.381,
      "step": 2100
    },
    {
      "epoch": 0.23908812899638587,
      "grad_norm": 1.1915068626403809,
      "learning_rate": 9.055435013033715e-05,
      "loss": 2.3662,
      "step": 2150
    },
    {
      "epoch": 0.24464831804281345,
      "grad_norm": 1.164106845855713,
      "learning_rate": 9.000977577979147e-05,
      "loss": 2.3874,
      "step": 2200
    },
    {
      "epoch": 0.25020850708924103,
      "grad_norm": 1.11827552318573,
      "learning_rate": 8.945167532209979e-05,
      "loss": 2.3961,
      "step": 2250
    },
    {
      "epoch": 0.2557686961356686,
      "grad_norm": 1.0562467575073242,
      "learning_rate": 8.88802374343152e-05,
      "loss": 2.4126,
      "step": 2300
    },
    {
      "epoch": 0.2613288851820962,
      "grad_norm": 1.0623661279678345,
      "learning_rate": 8.829565530247657e-05,
      "loss": 2.3758,
      "step": 2350
    },
    {
      "epoch": 0.26688907422852376,
      "grad_norm": 1.07105553150177,
      "learning_rate": 8.769812655629799e-05,
      "loss": 2.3878,
      "step": 2400
    },
    {
      "epoch": 0.26688907422852376,
      "eval_loss": 2.4327285289764404,
      "eval_runtime": 1067.3086,
      "eval_samples_per_second": 67.384,
      "eval_steps_per_second": 4.212,
      "step": 2400
    },
    {
      "epoch": 0.27244926327495134,
      "grad_norm": 1.071636438369751,
      "learning_rate": 8.70878532023563e-05,
      "loss": 2.3851,
      "step": 2450
    },
    {
      "epoch": 0.2780094523213789,
      "grad_norm": 1.0186628103256226,
      "learning_rate": 8.646504155579856e-05,
      "loss": 2.395,
      "step": 2500
    },
    {
      "epoch": 0.2835696413678065,
      "grad_norm": 1.0871504545211792,
      "learning_rate": 8.582990217059311e-05,
      "loss": 2.3659,
      "step": 2550
    },
    {
      "epoch": 0.28912983041423407,
      "grad_norm": 1.1816675662994385,
      "learning_rate": 8.518264976834758e-05,
      "loss": 2.4222,
      "step": 2600
    },
    {
      "epoch": 0.29469001946066165,
      "grad_norm": 1.0278229713439941,
      "learning_rate": 8.452350316571798e-05,
      "loss": 2.3749,
      "step": 2650
    },
    {
      "epoch": 0.3002502085070892,
      "grad_norm": 1.094319462776184,
      "learning_rate": 8.385268520043331e-05,
      "loss": 2.3866,
      "step": 2700
    },
    {
      "epoch": 0.3058103975535168,
      "grad_norm": 1.0301092863082886,
      "learning_rate": 8.317042265596077e-05,
      "loss": 2.3715,
      "step": 2750
    },
    {
      "epoch": 0.3113705865999444,
      "grad_norm": 0.9625698328018188,
      "learning_rate": 8.24769461848371e-05,
      "loss": 2.3855,
      "step": 2800
    },
    {
      "epoch": 0.31693077564637195,
      "grad_norm": 1.1198536157608032,
      "learning_rate": 8.177249023069187e-05,
      "loss": 2.3519,
      "step": 2850
    },
    {
      "epoch": 0.32249096469279953,
      "grad_norm": 1.159947156906128,
      "learning_rate": 8.105729294898906e-05,
      "loss": 2.3837,
      "step": 2900
    },
    {
      "epoch": 0.3280511537392271,
      "grad_norm": 1.0503102540969849,
      "learning_rate": 8.033159612651392e-05,
      "loss": 2.3715,
      "step": 2950
    },
    {
      "epoch": 0.3336113427856547,
      "grad_norm": 1.0585367679595947,
      "learning_rate": 7.959564509963198e-05,
      "loss": 2.3996,
      "step": 3000
    },
    {
      "epoch": 0.3391715318320823,
      "grad_norm": 1.0773338079452515,
      "learning_rate": 7.884968867134824e-05,
      "loss": 2.3866,
      "step": 3050
    },
    {
      "epoch": 0.3447317208785099,
      "grad_norm": 1.041317343711853,
      "learning_rate": 7.809397902719433e-05,
      "loss": 2.3427,
      "step": 3100
    },
    {
      "epoch": 0.3502919099249375,
      "grad_norm": 1.1744111776351929,
      "learning_rate": 7.732877164997213e-05,
      "loss": 2.3545,
      "step": 3150
    },
    {
      "epoch": 0.35585209897136505,
      "grad_norm": 1.0683200359344482,
      "learning_rate": 7.655432523338262e-05,
      "loss": 2.369,
      "step": 3200
    },
    {
      "epoch": 0.35585209897136505,
      "eval_loss": 2.41166353225708,
      "eval_runtime": 1067.149,
      "eval_samples_per_second": 67.395,
      "eval_steps_per_second": 4.212,
      "step": 3200
    },
    {
      "epoch": 0.3614122880177926,
      "grad_norm": 1.085188627243042,
      "learning_rate": 7.577090159456942e-05,
      "loss": 2.3807,
      "step": 3250
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 1.0257830619812012,
      "learning_rate": 7.497876558560607e-05,
      "loss": 2.3835,
      "step": 3300
    },
    {
      "epoch": 0.3725326661106478,
      "grad_norm": 1.036346673965454,
      "learning_rate": 7.417818500395768e-05,
      "loss": 2.358,
      "step": 3350
    },
    {
      "epoch": 0.37809285515707536,
      "grad_norm": 1.0147498846054077,
      "learning_rate": 7.336943050194644e-05,
      "loss": 2.3781,
      "step": 3400
    },
    {
      "epoch": 0.38365304420350294,
      "grad_norm": 1.0968035459518433,
      "learning_rate": 7.255277549525229e-05,
      "loss": 2.3433,
      "step": 3450
    },
    {
      "epoch": 0.3892132332499305,
      "grad_norm": 1.075219750404358,
      "learning_rate": 7.172849607047922e-05,
      "loss": 2.3524,
      "step": 3500
    },
    {
      "epoch": 0.3947734222963581,
      "grad_norm": 1.0828092098236084,
      "learning_rate": 7.089687089181874e-05,
      "loss": 2.3509,
      "step": 3550
    },
    {
      "epoch": 0.40033361134278567,
      "grad_norm": 1.0860296487808228,
      "learning_rate": 7.005818110684165e-05,
      "loss": 2.4009,
      "step": 3600
    },
    {
      "epoch": 0.40589380038921324,
      "grad_norm": 1.205290675163269,
      "learning_rate": 6.921271025145071e-05,
      "loss": 2.3502,
      "step": 3650
    },
    {
      "epoch": 0.4114539894356408,
      "grad_norm": 1.1278678178787231,
      "learning_rate": 6.836074415402553e-05,
      "loss": 2.3494,
      "step": 3700
    },
    {
      "epoch": 0.4170141784820684,
      "grad_norm": 1.2426846027374268,
      "learning_rate": 6.750257083879251e-05,
      "loss": 2.3463,
      "step": 3750
    },
    {
      "epoch": 0.422574367528496,
      "grad_norm": 1.09083890914917,
      "learning_rate": 6.663848042845258e-05,
      "loss": 2.371,
      "step": 3800
    },
    {
      "epoch": 0.42813455657492355,
      "grad_norm": 1.1175947189331055,
      "learning_rate": 6.576876504609929e-05,
      "loss": 2.3568,
      "step": 3850
    },
    {
      "epoch": 0.43369474562135113,
      "grad_norm": 1.1069817543029785,
      "learning_rate": 6.489371871646082e-05,
      "loss": 2.3501,
      "step": 3900
    },
    {
      "epoch": 0.4392549346677787,
      "grad_norm": 1.120945692062378,
      "learning_rate": 6.401363726649902e-05,
      "loss": 2.3617,
      "step": 3950
    },
    {
      "epoch": 0.4448151237142063,
      "grad_norm": 1.1357296705245972,
      "learning_rate": 6.312881822539913e-05,
      "loss": 2.3488,
      "step": 4000
    },
    {
      "epoch": 0.4448151237142063,
      "eval_loss": 2.3998634815216064,
      "eval_runtime": 1067.4539,
      "eval_samples_per_second": 67.375,
      "eval_steps_per_second": 4.211,
      "step": 4000
    },
    {
      "epoch": 0.45037531276063386,
      "grad_norm": 1.08186674118042,
      "learning_rate": 6.223956072398407e-05,
      "loss": 2.3448,
      "step": 4050
    },
    {
      "epoch": 0.45593550180706144,
      "grad_norm": 1.1602946519851685,
      "learning_rate": 6.134616539358731e-05,
      "loss": 2.3609,
      "step": 4100
    },
    {
      "epoch": 0.461495690853489,
      "grad_norm": 1.053074836730957,
      "learning_rate": 6.0448934264418414e-05,
      "loss": 2.3429,
      "step": 4150
    },
    {
      "epoch": 0.4670558798999166,
      "grad_norm": 1.1377049684524536,
      "learning_rate": 5.954817066345564e-05,
      "loss": 2.3476,
      "step": 4200
    },
    {
      "epoch": 0.47261606894634417,
      "grad_norm": 1.1343979835510254,
      "learning_rate": 5.864417911190017e-05,
      "loss": 2.3487,
      "step": 4250
    },
    {
      "epoch": 0.47817625799277175,
      "grad_norm": 1.2579047679901123,
      "learning_rate": 5.77372652222266e-05,
      "loss": 2.3582,
      "step": 4300
    },
    {
      "epoch": 0.4837364470391993,
      "grad_norm": 1.147415280342102,
      "learning_rate": 5.682773559486462e-05,
      "loss": 2.3485,
      "step": 4350
    },
    {
      "epoch": 0.4892966360856269,
      "grad_norm": 1.08349609375,
      "learning_rate": 5.591589771454644e-05,
      "loss": 2.3435,
      "step": 4400
    },
    {
      "epoch": 0.4948568251320545,
      "grad_norm": 1.1338609457015991,
      "learning_rate": 5.500205984635549e-05,
      "loss": 2.3356,
      "step": 4450
    },
    {
      "epoch": 0.5004170141784821,
      "grad_norm": 1.1571884155273438,
      "learning_rate": 5.4086530931511216e-05,
      "loss": 2.3462,
      "step": 4500
    },
    {
      "epoch": 0.5059772032249097,
      "grad_norm": 1.173668622970581,
      "learning_rate": 5.3169620482925306e-05,
      "loss": 2.3313,
      "step": 4550
    },
    {
      "epoch": 0.5115373922713372,
      "grad_norm": 1.1519402265548706,
      "learning_rate": 5.2251638480564654e-05,
      "loss": 2.3227,
      "step": 4600
    },
    {
      "epoch": 0.5170975813177648,
      "grad_norm": 1.0947030782699585,
      "learning_rate": 5.1332895266656344e-05,
      "loss": 2.3371,
      "step": 4650
    },
    {
      "epoch": 0.5226577703641924,
      "grad_norm": 1.073782205581665,
      "learning_rate": 5.0413701440770336e-05,
      "loss": 2.3321,
      "step": 4700
    },
    {
      "epoch": 0.52821795941062,
      "grad_norm": 1.1197625398635864,
      "learning_rate": 4.949436775481502e-05,
      "loss": 2.3163,
      "step": 4750
    },
    {
      "epoch": 0.5337781484570475,
      "grad_norm": 1.1181737184524536,
      "learning_rate": 4.8575205007981235e-05,
      "loss": 2.3583,
      "step": 4800
    },
    {
      "epoch": 0.5337781484570475,
      "eval_loss": 2.3899307250976562,
      "eval_runtime": 1068.1861,
      "eval_samples_per_second": 67.329,
      "eval_steps_per_second": 4.208,
      "step": 4800
    },
    {
      "epoch": 0.5393383375034752,
      "grad_norm": 1.1407630443572998,
      "learning_rate": 4.7656523941670464e-05,
      "loss": 2.3318,
      "step": 4850
    },
    {
      "epoch": 0.5448985265499027,
      "grad_norm": 1.164520263671875,
      "learning_rate": 4.6738635134442386e-05,
      "loss": 2.3323,
      "step": 4900
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 1.1389617919921875,
      "learning_rate": 4.582184889701768e-05,
      "loss": 2.3214,
      "step": 4950
    },
    {
      "epoch": 0.5560189046427578,
      "grad_norm": 1.1831128597259521,
      "learning_rate": 4.4906475167371135e-05,
      "loss": 2.336,
      "step": 5000
    },
    {
      "epoch": 0.5615790936891855,
      "grad_norm": 1.1420105695724487,
      "learning_rate": 4.399282340595095e-05,
      "loss": 2.3292,
      "step": 5050
    },
    {
      "epoch": 0.567139282735613,
      "grad_norm": 1.2305783033370972,
      "learning_rate": 4.3081202491059446e-05,
      "loss": 2.3434,
      "step": 5100
    },
    {
      "epoch": 0.5726994717820406,
      "grad_norm": 1.128121018409729,
      "learning_rate": 4.217192061443057e-05,
      "loss": 2.2979,
      "step": 5150
    },
    {
      "epoch": 0.5782596608284681,
      "grad_norm": 1.1207524538040161,
      "learning_rate": 4.126528517703942e-05,
      "loss": 2.3006,
      "step": 5200
    },
    {
      "epoch": 0.5838198498748958,
      "grad_norm": 1.202797532081604,
      "learning_rate": 4.0361602685179265e-05,
      "loss": 2.3423,
      "step": 5250
    },
    {
      "epoch": 0.5893800389213233,
      "grad_norm": 1.1244505643844604,
      "learning_rate": 3.946117864684089e-05,
      "loss": 2.3175,
      "step": 5300
    },
    {
      "epoch": 0.5949402279677509,
      "grad_norm": 1.1359913349151611,
      "learning_rate": 3.8564317468429555e-05,
      "loss": 2.3221,
      "step": 5350
    },
    {
      "epoch": 0.6005004170141784,
      "grad_norm": 1.1791000366210938,
      "learning_rate": 3.767132235185424e-05,
      "loss": 2.3395,
      "step": 5400
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 1.1248958110809326,
      "learning_rate": 3.678249519202416e-05,
      "loss": 2.3075,
      "step": 5450
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.1388715505599976,
      "learning_rate": 3.58981364747872e-05,
      "loss": 2.3409,
      "step": 5500
    },
    {
      "epoch": 0.6171809841534612,
      "grad_norm": 1.156822919845581,
      "learning_rate": 3.5018545175344595e-05,
      "loss": 2.2965,
      "step": 5550
    },
    {
      "epoch": 0.6227411731998888,
      "grad_norm": 1.2193772792816162,
      "learning_rate": 3.414401865717635e-05,
      "loss": 2.2965,
      "step": 5600
    },
    {
      "epoch": 0.6227411731998888,
      "eval_loss": 2.3844597339630127,
      "eval_runtime": 1067.1806,
      "eval_samples_per_second": 67.393,
      "eval_steps_per_second": 4.212,
      "step": 5600
    },
    {
      "epoch": 0.6283013622463164,
      "grad_norm": 1.1563918590545654,
      "learning_rate": 3.3274852571511606e-05,
      "loss": 2.3228,
      "step": 5650
    },
    {
      "epoch": 0.6338615512927439,
      "grad_norm": 1.1891727447509766,
      "learning_rate": 3.241134075737777e-05,
      "loss": 2.3398,
      "step": 5700
    },
    {
      "epoch": 0.6394217403391715,
      "grad_norm": 1.2056223154067993,
      "learning_rate": 3.1553775142262396e-05,
      "loss": 2.3218,
      "step": 5750
    },
    {
      "epoch": 0.6449819293855991,
      "grad_norm": 1.14029061794281,
      "learning_rate": 3.0702445643421164e-05,
      "loss": 2.3289,
      "step": 5800
    },
    {
      "epoch": 0.6505421184320267,
      "grad_norm": 1.2116241455078125,
      "learning_rate": 2.9857640069865568e-05,
      "loss": 2.3289,
      "step": 5850
    },
    {
      "epoch": 0.6561023074784542,
      "grad_norm": 1.1660765409469604,
      "learning_rate": 2.9019644025063335e-05,
      "loss": 2.3284,
      "step": 5900
    },
    {
      "epoch": 0.6616624965248818,
      "grad_norm": 1.1411018371582031,
      "learning_rate": 2.8188740810384423e-05,
      "loss": 2.3484,
      "step": 5950
    },
    {
      "epoch": 0.6672226855713094,
      "grad_norm": 1.3562407493591309,
      "learning_rate": 2.7365211329325302e-05,
      "loss": 2.3194,
      "step": 6000
    },
    {
      "epoch": 0.672782874617737,
      "grad_norm": 1.1583192348480225,
      "learning_rate": 2.654933399254391e-05,
      "loss": 2.2986,
      "step": 6050
    },
    {
      "epoch": 0.6783430636641646,
      "grad_norm": 1.123748779296875,
      "learning_rate": 2.574138462373733e-05,
      "loss": 2.3603,
      "step": 6100
    },
    {
      "epoch": 0.6839032527105922,
      "grad_norm": 1.1689674854278564,
      "learning_rate": 2.4941636366394076e-05,
      "loss": 2.3254,
      "step": 6150
    },
    {
      "epoch": 0.6894634417570198,
      "grad_norm": 1.1776434183120728,
      "learning_rate": 2.4150359591452454e-05,
      "loss": 2.3021,
      "step": 6200
    },
    {
      "epoch": 0.6950236308034473,
      "grad_norm": 1.272591233253479,
      "learning_rate": 2.3367821805896217e-05,
      "loss": 2.3368,
      "step": 6250
    },
    {
      "epoch": 0.700583819849875,
      "grad_norm": 1.198341965675354,
      "learning_rate": 2.25942875623185e-05,
      "loss": 2.317,
      "step": 6300
    },
    {
      "epoch": 0.7061440088963025,
      "grad_norm": 1.148457646369934,
      "learning_rate": 2.18300183694845e-05,
      "loss": 2.3308,
      "step": 6350
    },
    {
      "epoch": 0.7117041979427301,
      "grad_norm": 1.1431312561035156,
      "learning_rate": 2.107527260392318e-05,
      "loss": 2.2952,
      "step": 6400
    },
    {
      "epoch": 0.7117041979427301,
      "eval_loss": 2.379802942276001,
      "eval_runtime": 1067.7825,
      "eval_samples_per_second": 67.355,
      "eval_steps_per_second": 4.21,
      "step": 6400
    },
    {
      "epoch": 0.7172643869891576,
      "grad_norm": 1.1583247184753418,
      "learning_rate": 2.033030542257791e-05,
      "loss": 2.2954,
      "step": 6450
    },
    {
      "epoch": 0.7228245760355853,
      "grad_norm": 1.16840398311615,
      "learning_rate": 1.9595368676545545e-05,
      "loss": 2.3209,
      "step": 6500
    },
    {
      "epoch": 0.7283847650820128,
      "grad_norm": 1.1595884561538696,
      "learning_rate": 1.887071082593312e-05,
      "loss": 2.3004,
      "step": 6550
    },
    {
      "epoch": 0.7339449541284404,
      "grad_norm": 1.217913269996643,
      "learning_rate": 1.8156576855860897e-05,
      "loss": 2.3349,
      "step": 6600
    },
    {
      "epoch": 0.7395051431748679,
      "grad_norm": 1.3129838705062866,
      "learning_rate": 1.7453208193640276e-05,
      "loss": 2.3011,
      "step": 6650
    },
    {
      "epoch": 0.7450653322212956,
      "grad_norm": 1.1898494958877563,
      "learning_rate": 1.6760842627154404e-05,
      "loss": 2.3185,
      "step": 6700
    },
    {
      "epoch": 0.7506255212677231,
      "grad_norm": 1.194419503211975,
      "learning_rate": 1.607971422446926e-05,
      "loss": 2.3107,
      "step": 6750
    },
    {
      "epoch": 0.7561857103141507,
      "grad_norm": 1.271362543106079,
      "learning_rate": 1.5410053254702206e-05,
      "loss": 2.3107,
      "step": 6800
    },
    {
      "epoch": 0.7617458993605782,
      "grad_norm": 1.3185497522354126,
      "learning_rate": 1.4752086110174913e-05,
      "loss": 2.2934,
      "step": 6850
    },
    {
      "epoch": 0.7673060884070059,
      "grad_norm": 1.246860384941101,
      "learning_rate": 1.4106035229876913e-05,
      "loss": 2.3536,
      "step": 6900
    },
    {
      "epoch": 0.7728662774534334,
      "grad_norm": 1.1600207090377808,
      "learning_rate": 1.34721190242656e-05,
      "loss": 2.3114,
      "step": 6950
    },
    {
      "epoch": 0.778426466499861,
      "grad_norm": 1.1526597738265991,
      "learning_rate": 1.2850551801428229e-05,
      "loss": 2.3064,
      "step": 7000
    },
    {
      "epoch": 0.7839866555462885,
      "grad_norm": 1.2916783094406128,
      "learning_rate": 1.2241543694630746e-05,
      "loss": 2.316,
      "step": 7050
    },
    {
      "epoch": 0.7895468445927162,
      "grad_norm": 1.2395199537277222,
      "learning_rate": 1.1645300591278047e-05,
      "loss": 2.3113,
      "step": 7100
    },
    {
      "epoch": 0.7951070336391437,
      "grad_norm": 1.2001597881317139,
      "learning_rate": 1.1062024063309573e-05,
      "loss": 2.3188,
      "step": 7150
    },
    {
      "epoch": 0.8006672226855713,
      "grad_norm": 1.1841574907302856,
      "learning_rate": 1.0491911299053908e-05,
      "loss": 2.2991,
      "step": 7200
    },
    {
      "epoch": 0.8006672226855713,
      "eval_loss": 2.3757903575897217,
      "eval_runtime": 1067.4724,
      "eval_samples_per_second": 67.374,
      "eval_steps_per_second": 4.211,
      "step": 7200
    },
    {
      "epoch": 0.8062274117319989,
      "grad_norm": 1.1560871601104736,
      "learning_rate": 9.935155036565307e-06,
      "loss": 2.3359,
      "step": 7250
    },
    {
      "epoch": 0.8117876007784265,
      "grad_norm": 1.1857982873916626,
      "learning_rate": 9.391943498464707e-06,
      "loss": 2.3247,
      "step": 7300
    },
    {
      "epoch": 0.817347789824854,
      "grad_norm": 1.1491162776947021,
      "learning_rate": 8.862460328307315e-06,
      "loss": 2.2984,
      "step": 7350
    },
    {
      "epoch": 0.8229079788712816,
      "grad_norm": 1.2488857507705688,
      "learning_rate": 8.346884528498223e-06,
      "loss": 2.327,
      "step": 7400
    },
    {
      "epoch": 0.8284681679177092,
      "grad_norm": 1.1904360055923462,
      "learning_rate": 7.845390399777043e-06,
      "loss": 2.312,
      "step": 7450
    },
    {
      "epoch": 0.8340283569641368,
      "grad_norm": 1.1962580680847168,
      "learning_rate": 7.358147482292038e-06,
      "loss": 2.2914,
      "step": 7500
    },
    {
      "epoch": 0.8395885460105643,
      "grad_norm": 1.2207309007644653,
      "learning_rate": 6.885320498283715e-06,
      "loss": 2.3085,
      "step": 7550
    },
    {
      "epoch": 0.845148735056992,
      "grad_norm": 1.1619229316711426,
      "learning_rate": 6.427069296397115e-06,
      "loss": 2.3146,
      "step": 7600
    },
    {
      "epoch": 0.8507089241034195,
      "grad_norm": 1.2419124841690063,
      "learning_rate": 5.983548797641819e-06,
      "loss": 2.3059,
      "step": 7650
    },
    {
      "epoch": 0.8562691131498471,
      "grad_norm": 1.1977388858795166,
      "learning_rate": 5.55490894301775e-06,
      "loss": 2.3042,
      "step": 7700
    },
    {
      "epoch": 0.8618293021962746,
      "grad_norm": 1.2282679080963135,
      "learning_rate": 5.141294642824651e-06,
      "loss": 2.3116,
      "step": 7750
    },
    {
      "epoch": 0.8673894912427023,
      "grad_norm": 1.2203304767608643,
      "learning_rate": 4.742845727672235e-06,
      "loss": 2.2853,
      "step": 7800
    },
    {
      "epoch": 0.8729496802891298,
      "grad_norm": 1.2240052223205566,
      "learning_rate": 4.359696901207627e-06,
      "loss": 2.3261,
      "step": 7850
    },
    {
      "epoch": 0.8785098693355574,
      "grad_norm": 1.2470169067382812,
      "learning_rate": 3.991977694576127e-06,
      "loss": 2.3183,
      "step": 7900
    },
    {
      "epoch": 0.8840700583819849,
      "grad_norm": 1.2669942378997803,
      "learning_rate": 3.639812422630573e-06,
      "loss": 2.3027,
      "step": 7950
    },
    {
      "epoch": 0.8896302474284126,
      "grad_norm": 1.2248331308364868,
      "learning_rate": 3.3033201419042482e-06,
      "loss": 2.3132,
      "step": 8000
    },
    {
      "epoch": 0.8896302474284126,
      "eval_loss": 2.374586343765259,
      "eval_runtime": 1067.5374,
      "eval_samples_per_second": 67.37,
      "eval_steps_per_second": 4.211,
      "step": 8000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8993,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 800,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1901568529707827e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
